{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.10.29</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.26</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.24</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이 정도면 볼만하다고 할 수 있음!</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.22</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>재미있다</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.20</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating        date  \\\n",
       "0                             돈 들인건 티가 나지만 보는 내내 하품만       1  2018.10.29   \n",
       "1       몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.      10  2018.10.26   \n",
       "2  이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...       8  2018.10.24   \n",
       "3                                이 정도면 볼만하다고 할 수 있음!       8  2018.10.22   \n",
       "4                                               재미있다      10  2018.10.20   \n",
       "\n",
       "    title  \n",
       "0  인피니티 워  \n",
       "1  인피니티 워  \n",
       "2  인피니티 워  \n",
       "3  인피니티 워  \n",
       "4  인피니티 워  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"daum_movie_review.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "신과함께      4947\n",
       "택시운전사     2322\n",
       "인피니티 워    2042\n",
       "범죄도시      1939\n",
       "곤지암       1547\n",
       "라라랜드      1150\n",
       "코코         778\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 11043\n",
      "train size: 3682\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터, 테스트 데이터 분리 \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.review, df.title, random_state=42)\n",
    "\n",
    "print('train size:' , len(X_train))\n",
    "print('train size:' , len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['몰입', '할수밖에', '없다', '.', '어렵게', '생각', '할', '필요없다', '.', '내', '가', '전투', '에', '참여', '한', '듯', '손', '에', '땀', '이남', '.']\n",
      "['몰입', '생각', '내', '전투', '참여', '듯', '손', '땀', '이남']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "print(okt.morphs(X_train[1]))\n",
    "print(okt.nouns(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도: 0.7584895408856289\n",
      "테스트 정확도: 0.6852254209668658\n"
     ]
    }
   ],
   "source": [
    "# 명사를 tfidf 토크나이저로 지정해 로지스틱 회귀 분석 실행 \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=okt.nouns, max_features=2000, min_df=5, max_df=0.5)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000) # 반복율 1000, 디폴트 100\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('훈련 정확도: {:3}'.format(clf.score(X_train_tfidf,y_train)))\n",
    "\n",
    "print('테스트 정확도: {:3}'.format(clf.score(X_test_tfidf,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제 영화 제목, 예측한 제목, 리뷰내용\n",
      "('인피니티 워', '인피니티 워', '누가 죽는다는겁니까? 마블 영화는  한번도 본적이 없어서  스파이더맨3가 마지막')\n",
      "('신과함께', '신과함께', '재밋습니다')\n",
      "('범죄도시', '택시운전사', '윤ㄱㅖ상 양옆의 똘마니들은 누군가요 진짜 미친놈 같음ㅎㄷㄷ')\n",
      "('인피니티 워', '인피니티 워', '완전 허무 마지막 컷에서 타노스는 돌아온다 ㅋㅋㅋㅋ 개봉전 떠돌던 아이언맨과 캡틴은 살았슴.. 다른 배우들이 문제지.... 쩝')\n",
      "('범죄도시', '신과함께', '스토리는 없음. 지루하지는 않았으나 7점 정도가 적당한거 같은데....타짜하고 추격자 이상인지는 모르겠음')\n",
      "('코코', '코코', \"이제 막 6살된 딸이랑 보러갔습니다. 딸에게는 다소 어려운 세계관이었는지, 보는 내내 여러 질문들을 하기는 했습니다. 딸도 잘 이해는 못하지만, 재미있게 봤다고 하고, 저 역시 약간의 감동과 재미가 남는 애니메이션이었습니다. 딸아이가 영화보고 나오자 마자 '기억해줘'를 틀어달라고 하네요 ㅎㅎ\")\n",
      "('범죄도시', '신과함께', '재밌어요')\n",
      "('인피니티 워', '신과함께', '잼있어 빵점 준다')\n",
      "('라라랜드', '라라랜드', '작년에 본 영화중에 가장 행복했던 영화.. 지인이 라라랜드 보러가자고 해서 무슨 영화 제목이 그러냐고 했다가 지금까지 OST 듣고 다닌다지.. 개인적으로 엔딩까지 훌륭했던 영화')\n",
      "('신과함께', '신과함께', '내용은 생각보다 넘 재미없내요 노잼 노잼 영상은 굿-')\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 예측 \n",
    "\n",
    "print('실제 영화 제목, 예측한 제목, 리뷰내용')\n",
    "\n",
    "for content in zip(y_test[:10], clf.predict(X_test_tfidf[:10]), X_test[:10]):\n",
    "    print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도: 0.7790455492166983\n",
      "테스트 정확도: 0.6936447582835416\n"
     ]
    }
   ],
   "source": [
    "#품사를 사용하여 예측 \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=okt.morphs, max_features=2000, min_df=5, max_df=0.5)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)  # 반복율 1000, 디폴트 100\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"훈련 정확도: {:3}\".format(clf.score(X_train_tfidf, y_train)))\n",
    "\n",
    "print(\"테스트 정확도: {:3}\".format(clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('몰입', 'Noun'), ('할수밖에', 'Verb'), ('없다', 'Adjective'), ('.', 'Punctuation'), ('어렵게', 'Adjective'), ('생각', 'Noun'), ('할', 'Verb'), ('필요없다', 'Adjective'), ('.', 'Punctuation'), ('내', 'Noun'), ('가', 'Josa'), ('전투', 'Noun'), ('에', 'Josa'), ('참여', 'Noun'), ('한', 'Determiner'), ('듯', 'Noun'), ('손', 'Noun'), ('에', 'Josa'), ('땀', 'Noun'), ('이남', 'Noun'), ('.', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "# 품사 표시 \n",
    "print(okt.pos(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명사, 동사, 형용사만 선별 \n",
    "def twit_tokenizer(text):\n",
    "    target_tags = ['Nouns', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in okt.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도: 0.7790455492166983\n",
      "테스트 정확도: 0.6936447582835416\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=okt.morphs, max_features=2000, min_df=5, max_df=0.5)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)  # 반복율 1000, 디폴트 100\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"훈련 정확도: {:3}\".format(clf.score(X_train_tfidf, y_train)))\n",
    "\n",
    "print(\"테스트 정확도: {:3}\".format(clf.score(X_test_tfidf, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제 영화 제목, 예측한 제목, 리뷰내용\n",
      "('인피니티 워', '인피니티 워', '누가 죽는다는겁니까? 마블 영화는  한번도 본적이 없어서  스파이더맨3가 마지막')\n",
      "('신과함께', '인피니티 워', '재밋습니다')\n",
      "('범죄도시', '인피니티 워', '윤ㄱㅖ상 양옆의 똘마니들은 누군가요 진짜 미친놈 같음ㅎㄷㄷ')\n",
      "('인피니티 워', '인피니티 워', '완전 허무 마지막 컷에서 타노스는 돌아온다 ㅋㅋㅋㅋ 개봉전 떠돌던 아이언맨과 캡틴은 살았슴.. 다른 배우들이 문제지.... 쩝')\n",
      "('범죄도시', '신과함께', '스토리는 없음. 지루하지는 않았으나 7점 정도가 적당한거 같은데....타짜하고 추격자 이상인지는 모르겠음')\n",
      "('코코', '코코', \"이제 막 6살된 딸이랑 보러갔습니다. 딸에게는 다소 어려운 세계관이었는지, 보는 내내 여러 질문들을 하기는 했습니다. 딸도 잘 이해는 못하지만, 재미있게 봤다고 하고, 저 역시 약간의 감동과 재미가 남는 애니메이션이었습니다. 딸아이가 영화보고 나오자 마자 '기억해줘'를 틀어달라고 하네요 ㅎㅎ\")\n",
      "('범죄도시', '신과함께', '재밌어요')\n",
      "('인피니티 워', '인피니티 워', '잼있어 빵점 준다')\n",
      "('라라랜드', '라라랜드', '작년에 본 영화중에 가장 행복했던 영화.. 지인이 라라랜드 보러가자고 해서 무슨 영화 제목이 그러냐고 했다가 지금까지 OST 듣고 다닌다지.. 개인적으로 엔딩까지 훌륭했던 영화')\n",
      "('신과함께', '신과함께', '내용은 생각보다 넘 재미없내요 노잼 노잼 영상은 굿-')\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 예측\n",
    "\n",
    "print(\"실제 영화 제목, 예측한 제목, 리뷰내용\")\n",
    "\n",
    "for content in zip(y_test[:10], clf.predict(X_test_tfidf[:10]), X_test[:10]):\n",
    "    print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
