{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계로는 알 수 없는 문맥 정보\n",
    "\n",
    "\n",
    "- 지금까지 BOW 기반의 방법을 이용해서 다양한 분류 기법을 수행했다.\n",
    "- 하지만 여기에는 문제가 있다. 단어들이 쓰여진 순서에 따른 문맥 정보를 이용할 수 없다는 것이다.\n",
    "- 기본적으로 BOW 방식은 단어들의 순서를 무시하고, 단어가 사용된 횟수를 기반으로 문서에 대한 벡터를 만든다.\n",
    "- 이러한 문제점을 해결하기 위해 제시된 방법은 문서를 다어들의 통계적인 값으로 표현하지 않고,\n",
    "- 있는 그래도 단어의 시퀀스로 표현해서 처리하는 것ㄷ이다.\n",
    "- 딥러닝 기법은 이와 같은 요구에 의해 사용되기 시작했다.\n",
    "- 딥러닝 기법 대신 BOW 방식을 그대로 쓰면서도 단어가 쓰여진 순서를 반영할 수 있는 방법이 N-gram이다.\n",
    "\n",
    "\n",
    "## N-gram\n",
    "- n-gram은 n개의 연속적인 단어들의 나열을 의미한다.\n",
    "- 이는 하나의 토클이 두개 이상의 단어로 구성될 수 있는데 n이 2이면 bi-gram이라 부른다.\n",
    "- 이 경우 하나의 토큰은 두 개의 단어로 구성된다.\n",
    "- unigram: the, future, depends, on, what, we, do, in, the, present\n",
    "- bi-gram: the future, future depends, depends on, on what...\n",
    "- tri-gram: the future depends, future depends on, depends on what...\n",
    "\n",
    "\n",
    "----\n",
    "- n-gram의 본래 용도는 언어 모델의 특성에 있다.\n",
    "- 언어 모델은 단어의 시퀀스에 대해 확률을 할당하는 모델을 말하는데, 이때 확률은 말뭉치에 나타난 단어 시퀀스의 빈도와 관련이 있다.\n",
    "- 예를 들어 '배가 고파서 밥을 먹었다'와 '배가 고파서 밥을 치웠다' 중에서 앞 문장이 더 자연스럽다.\n",
    "- 언어 모델은 이 두 문장에 확률을 부여하는데, 컴퓨터는 어떻게 확률을 부여할까.\n",
    "- 확률을 계산하는데 참조하는 말뭉치에 앞 문장이 더 많이 나타나면 이를 기반으로 앞 문자에 더 높은 확률을 부여하면 된다.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "- 문제는 '나는 배가 고파서 밥을 허겁지겁 먹었다'라는 문장은 나온 적이 없을때다.\n",
    "- 이때 n-gram의 역할이 나온다.\n",
    "- 말뭉치에 앞에서부터 이어지는 전체 문장이 없더라도 '밥을 허겁지겁'과 같은 bi-gram 말뭉치 어딘가에 난타났다면 이 분장에 대한 확률이 0 이상이 될 수 있다.\n",
    "- 결국 bi-gram을 사용하면 적어도 두 단어로 이뤄진 시퀀스에 대해 파악하게 된다.\n",
    "- 따라서 아주 제한적이지만 문맥에 대한 정보를 추가한다고 볼 수 있다.\n",
    "- tri-gram을 사용하면 더 많은 정보를 얻을 수 있다.\n",
    "- 하지만 n을 계속 늘려갈 수는 없다.\n",
    "- 따라서 tri-gram 정도까지 쓰는 것이 알반적이다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트:  2034\n",
      "테스트 세트:  1353\n",
      "선택 토픽:  ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
      "훈련 라벨:  {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "\n",
    "# 데이터셋 로드 (train 데이터를 기준으로)\n",
    "# data = fetch_20newsgroups(subset='train')\n",
    "\n",
    "\n",
    "# 데이터셋의 컬럼(속성) 확인\n",
    "# print(data.keys())\n",
    "# print(data.target_names)\n",
    "\n",
    "\n",
    "# 20개의 토픽 중 선택하고자 하는 토픽을 리스트로 생성\n",
    "\n",
    "\n",
    "# 20개의 토픽 중 4개의 토픽을 리스트로 생성\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "\n",
    "# 학습 데이터셋 로드\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "# 메일 내용에서 hint가 되는 부분을 삭제 - 순수하게 내용만으로 분류\n",
    "                                      remove=('headers', 'footers', 'quotes'), # 토픽의 정보가 있는 경우 제외\n",
    "                                      categories=categories)\n",
    "\n",
    "\n",
    "# 평가 데이터셋을 가져옴\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "                                     remove=('headers', 'footers', 'quotes'),\n",
    "                                     categories=categories)\n",
    "\n",
    "\n",
    "print(\"훈련 세트: \", len(newsgroups_train.data))\n",
    "print(\"테스트 세트: \", len(newsgroups_test.data))\n",
    "print(\"선택 토픽: \", newsgroups_train.target_names)\n",
    "print(\"훈련 라벨: \", set(newsgroups_train.target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카운트 기반 특성 추출\n",
    "X_train = newsgroups_train.data\n",
    "Y_train = newsgroups_train.target\n",
    "\n",
    "\n",
    "X_test = newsgroups_test.data\n",
    "Y_test = newsgroups_test.target\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.5)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\3호실-09\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 12308)\n"
     ]
    }
   ],
   "source": [
    "# n-gram을 이용한 문서 분류 구현\n",
    "# unigram, bi-gram, tri-gram의 배교를 위해 Unigram으로 TfidfVectorizer 객체를 새로 생성하고\n",
    "# 변환된 TF-IDF 벡터의 크기를 확인한다.\n",
    "# n-gram에서 n이 바뀜에 따라 벡터의 크기가 어떻게 바뀌는지 보기 위해 max_features는 사용하지 않는다.\n",
    "# 그 외에 토큰화를 위한 정규식을 인수로 주고 불용어사전을 이용한다.\n",
    "\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    token_pattern=r\"(?u)\\b\\w\\w+\\b\",  # 토큰화를 위한 정규식\n",
    "    decode_error=\"ignore\",\n",
    "    lowercase=True,\n",
    "    stop_words=stopwords.words(\"english\"),  # 불용어사전\n",
    "    max_df=0.5,\n",
    "    min_df=2,\n",
    ")\n",
    "\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "\n",
    "print(X_train_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도:  0.976401179941003\n",
      "테스트 정확도:  0.770879526977088\n"
     ]
    }
   ],
   "source": [
    "# 릿지 회귀를 이용해 학습하고 성능 확인\n",
    "# n-gram을 사용하면 변수가 늘어나고 이로 인해 과적합의 우려가 있기 때문에 릿지 회귀분석을 사용한다.\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "ridge_clf = RidgeClassifier()\n",
    "ridge_clf.fit(X_train_tfidf, Y_train)\n",
    "print(\"훈련 정확도: \", ridge_clf.score(X_train_tfidf, Y_train))\n",
    "print(\"테스트 정확도: \", ridge_clf.score(X_test_tfidf, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 28145)\n"
     ]
    }
   ],
   "source": [
    "#bi-gram\n",
    "\n",
    "# TfidfVectorizer의 ngram_range 파라미터 사용 \n",
    "# 이 매개 변수는 () 안에 시작 n 값과 끝 n값으로 이뤄진 튜플이다 \n",
    "# (1,2)듀플 쓰면 유니그램 바이그램 모두 씀 \n",
    "# 바이그램은 (2,2)로 작성한다 \n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    token_pattern=r\"(?u)\\b\\w\\w+\\b\",  # 토큰화를 위한 정규식\n",
    "    decode_error=\"ignore\",\n",
    "    lowercase=True,\n",
    "    stop_words=stopwords.words(\"english\"),  # 불용어사전\n",
    "    max_df=0.5,\n",
    "    min_df=2,\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00 10', '00 pm', '00 pounds', '00 thank', '000 000', '000 100', '000 bytes', '000 feet', '000 foot', '000 km']\n"
     ]
    }
   ],
   "source": [
    "# 바이그램이 어떤 방식으로 생성되는지 확인하기 위해 특성 이름을 출력한다. \n",
    "bigram_features = [f for f in tfidf.get_feature_names_out() if len(f.split()) > 1]\n",
    "print(bigram_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성수를 늘린 후 릿지 훈련 세트 정확도 0.976\n",
      "특성수를 늘린 후 릿지 테스트 세트 정확도 0.78\n"
     ]
    }
   ],
   "source": [
    "# 바이그램으로 전환된 데이터를 통해 릿지 회귀 학습 \n",
    "ridge_clf.fit(X_train_tfidf, Y_train)\n",
    "print(\n",
    "    \"특성수를 늘린 후 릿지 훈련 세트 정확도 {:.3}\".format(\n",
    "        ridge_clf.score(X_train_tfidf, Y_train)\n",
    "    )\n",
    ")\n",
    "# 테스트 세트 정확도\n",
    "print(\n",
    "    \"특성수를 늘린 후 릿지 테스트 세트 정확도 {:.3}\".format(\n",
    "        ridge_clf.score(X_test_tfidf, Y_test)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 34974)\n"
     ]
    }
   ],
   "source": [
    "# 트라이 그램 사용 \n",
    "tfidf = TfidfVectorizer(\n",
    "    token_pattern=r\"(?u)\\b\\w\\w+\\b\",  # 토큰화를 위한 정규식\n",
    "    decode_error=\"ignore\",\n",
    "    lowercase=True,\n",
    "    stop_words=stopwords.words(\"english\"),  # 불용어사전\n",
    "    max_df=0.5,\n",
    "    min_df=2,\n",
    "    ngram_range=(1, 3)\n",
    ")\n",
    "\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00 pounds us', '00 thank helping', '000 000 scale', '0000 155 1150', '00000 11888 86', '00041032 00000 11888', '0004422 293 4650', '0028 300 1200', '01 14 39', '01 v2 00']\n"
     ]
    }
   ],
   "source": [
    "trigram_features = [f for f in tfidf.get_feature_names_out() if len(f.split()) > 2]\n",
    "print(trigram_features[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성수를 늘린 후 릿지 훈련 세트 정확도 0.976\n",
      "특성수를 늘린 후 릿지 테스트 세트 정확도 0.779\n"
     ]
    }
   ],
   "source": [
    "ridge_clf.fit(X_train_tfidf, Y_train)\n",
    "\n",
    "# 훈련 세트 정확도\n",
    "print(\n",
    "    \"특성수를 늘린 후 릿지 훈련 세트 정확도 {:.3}\".format(\n",
    "        ridge_clf.score(X_train_tfidf, Y_train)\n",
    "    )\n",
    ")\n",
    "\n",
    "# 테스트 세트 정확도\n",
    "print(\n",
    "    \"특성수를 늘린 후 릿지 테스트 세트 정확도 {:.3}\".format(\n",
    "        ridge_clf.score(X_test_tfidf, Y_test)\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
